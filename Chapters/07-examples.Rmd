# Examples of application {#Examples}
In this chapter we consider examples of application for cLR and the complex ARIMA models.


## cARIMA applied to Box-Jenkins Sales data
In this example, we consider the Box-Jenkins Sales data with a leading indicator. While typically the indicator is treated as an explanatory variable, we will treat the two as one joint complex variable. Separately, they have the dynamics shown in Figure \@ref(fig:BJSales).

```{r BJSales, fig.cap="Box-Jenkins Sales data with a leading indicator.", echo=FALSE}
par(mfcol=c(2,1), mar=c(2,4,2,1))
plot(BJsales)
plot(BJsales.lead)
```

As we can see they seem to change over time similarly, which is probably because the indicator drives the sales. But if we unite the two in one complex variable and plot their joint dynamics we will see that not only the values change over time, but also the relation between the variables (see Figure \@ref(fig:BJSalesComplex)).

```{r BJSalesComplex, fig.cap="Box-Jenkins Sales data. Complex dynamics. The red circle depicts the first observation, while the blue trianle is the last one.", echo=FALSE}
y <- complex(real=BJsales, imaginary=BJsales.lead)
plot(y, type="l")
points(head(y,1), pch=16, col="red")
points(tail(y,1), pch=17, col="blue")
```

While judgmentally we can conclude that both parts of this complex variable are non-stationary, we will conduct ADF and KPSS tests using `adf.test()` and `kpss.test()` functions from the `tseries` package after applying MDS to it. We will use 1% significance level in the hypotheses testing.

```{r}
# Normalise the variables
complex(real=BJsales, imaginary=BJsales.lead) |>
    cscale(scaling="norm") -> y
# Scale the complex variable into the real-valued one
yScaled <- cmdscale(dist(complex2vec(y)), k=1)
```

In the code above we use the `cscale()` function from the `complex` package to scale both parts of the complex variable. We can then conduct the ADF test:

```{r}
# Apply ADF test
tseries::adf.test(yScaled)
```

The output above shows that on 1% level we fail to reject the null hypothesis that the data is not stationary according to the ADF test. With KPSS, the final message is similar, because we reject the null hypothesis on the 1% significance level:

```{r}
tseries::kpss.test(yScaled)
```

If we take the first differences, the conclusions become contradictory:
```{r}
diff(yScaled) |>
    tseries::adf.test()
```

In the ADF test, we still fail to reject the null hypothesis on the 1% level (see output above), while in the KPSS test, we now fail to reject the null as well. This means that the ADF detects non-stationarity in the data, while the KPSS does not.

```{r}
diff(yScaled) |>
    tseries::kpss.test()
```

Given this contradiction, we plot the differences of the scaled data to make the conclusion judgmentally (Figure \@ref(fig:BJSalesComplexDiffs)):

```{r BJSalesComplexDiffs, fig.cap="First differences of the MDS of the complex variable of the Box-Jenkins Sales data.", echo=FALSE}
diff(yScaled) |>
    plot(type="l")
```

Analysing the series in Figure \@ref(fig:BJSalesComplexDiffs), it might be the case that the data contains a strong AR component or that it is non-stationary. Using this information, we will construct two models: cARIMA(p,2,q) and cARIMA(p,1,q) - and see, which of them performs better. Note that while in general the models are not comparable if different orders d are applied due to the loss of the number of in-sample observations, the `clm()` function takes care of potential missing values and extrapolates them back, making the models comparable.

Now we apply the cARIMA model to the newly constructed complex variable. We will try several special cases of cARIMA and choose the one that has the lowest information criterion. The code below shows how the process can be automated:

```{r eval=FALSE}
# Create all combinations of cARIMA orders to consider
# Here, we set d={1, 2} based on the earlier data exploration
expand.grid(c(0:3),c(1:2),c(0:3)) |>
    as.matrix() -> orders
colnames(orders) <- c("cAR","cI","cMA")
nModels <- nrow(orders)
# Prepare the list of all models under consideration
cARIMABJ <- vector("list",nModels)
names(cARIMABJ) <- paste0("cARIMA(",orders[,1],",",
                          orders[,2],",",orders[,3],")");

# Construct models
for(i in 1:nModels){
    cARIMABJ[[i]] <- clm(y~1, orders=orders[i,], subset=c(1:130))
}
```

```{r echo=FALSE}
load("./data/cARIMABJ.Rdata")
```

The script above will produce 32 cARIMA models of different orders. To choose the best one based on an information criterion, we will use the `AICc()` function from the `greybox` package in R:

```{r}
# Extract AICc values
cARIMABJAICc <- sapply(cARIMABJ, AICc)
# Fix names. Sometimes R makes silly things...
names(cARIMABJAICc) <- names(cARIMABJ)
# Record the index of the model with the lowest AICc
i <- which.min(cARIMABJAICc)
```

The summary of the best performing model is shown below:
```{r}
summary(cARIMABJ[[i]])
```

The output above shows the name of the model and the standard statistics we have already seen before. The forecast from this model for the next 20 observations is shown in Figure \@ref(fig:BJSalesComplexForecast).

```{r BJSalesComplexForecast, fig.cap="Forecast for the Box-Jenkins series.", echo=FALSE}
par(mfcol=c(2,1), mar=c(2,4,2,1))
predict(cARIMABJ[[i]], newdata=matrix(NA,20,1)) |>
    plot()
```

As we see, the model managed to capture the dynamics of the original data well, producing reasonable point forecasts for both parts. If we want to return to the original scale, we can use the `cdescale()` function from the `complex` package:

```{r}
yForecast <- predict(cARIMABJ[[i]],
                     newdata=matrix(NA,20,1))
cdescale(yForecast$mean,
         complex(real=BJsales, imaginary=BJsales.lead),
         scaling="norm")
```


## Seatbels law in the UK
In another example, we consider the time series data with several explanatory variables. This is the Road Casualties in Great Britain from 1969 to 1984, available in the `datasets` package in R. We do not need all the variables in the data, but we will use the following ones:

1. drivers - the number of car drivers killed or seriously injured;
2. killed - car drivers killed (from the `DriversKilled` variable);
3. injured - drivers injured (calculated as `drivers` - `DriversKilled`);
4. kms - distance driven by drivers;
5. PetrolPrice - average price of petrol in each month;
6. law - binary variable, indicating when the law for mandatory seatbelts was in effect.

The variables (2) and (3) will form our complex response variable, while (4), (5) and (6) will be used as explanatory ones. Note that in this setting we do not form complex variables from the explanatory ones and only have the complex response variable. The code below shows how this can be done:

```{r}
SeatbeltsData <- data.frame(killed=Seatbelts[,"DriversKilled"],
                            injured=Seatbelts[,"drivers"]-Seatbelts[,"DriversKilled"],
                            kms=Seatbelts[,"kms"],
                            PetrolPrice=Seatbelts[,"PetrolPrice"],
                            law=Seatbelts[,"law"])

SeatbeltsComplex <- data.frame(y=complex(real=SeatbeltsData$killed, imaginary=SeatbeltsData$injured),
                               kms=SeatbeltsData$kms, PetrolPrice=SeatbeltsData$PetrolPrice, law=SeatbeltsData$law)
```

Looking at the response variable, we would argue that a multiplicative model is needed, because the amplitude of seasonality in both variables changes when the seatbelts law is introduced (see Figure \@ref(fig:seatbeltsData)).

```{r seatbeltsData, fig.cap="Dynamics of number of drivers killed and injured in the Great Britain.", echo=FALSE}
par(mfcol=c(2,1),mar=c(4,4,1,1))
plot(Seatbelts[,"DriversKilled"],type="l", ylab="killed", xlab="Time")
plot(Seatbelts[,"drivers"]-Seatbelts[,"DriversKilled"],type="l", ylab="injured", xlab="Time")
```

Taking logarithm of the complex response variable would not be reasonable in this situation, because that would not fix the issue with the amplitude of seasonality. So, we can use the `clog()` function from the `complex` package to take logarithms of real and imaginary parts independently. Furthermore, given that both the real and the imaginary parts of the response variable are in the same units (number of drivers), we do not need to scale them. The only additional thing we need to do is to introduce a variable for seasonality, which can be done using `temporaldummy()` function from the `greybox` package:

```{r}
SeatbeltsComplex$seasonal <- temporaldummy(SeatbeltsComplex[,1],
                                           type="month", of="year", factors=TRUE)
```

We can then estimate a complex-valued model with real-valued explanatory variables, which should be equivalent to a multivariate linear regression. Note that we take logarithms of the numerical explanatory variables to capture the non-linearity correctly:

```{r}
SeatbeltscLR01 <- clm(I(clog(y))~log(kms)+log(PetrolPrice)+law+seasonal,
                      SeatbeltsComplex)
```

The output above shows the estimates of the parameters of the model, demonstrating how the model captured the relations in the data. The model fit is shown in Figure \@ref(fig:seatbeltsDataModel1).

```{r seatbeltsDataModel1, fig.cap="Number of drivers killed and injured and the fitted values.", echo=FALSE}
yStart <- start(Seatbelts)
yFreq <- frequency(Seatbelts)

yFitted <- ts(cexp(fitted(SeatbeltscLR01)), start=yStart, frequency=yFreq)

par(mfcol=c(2,1),mar=c(4,4,1,1))
plot(Seatbelts[,"DriversKilled"],type="l", ylab="killed", xlab="Time")
lines(Re(yFitted), col="purple", lwd=2, lty=2)

plot(Seatbelts[,"drivers"]-Seatbelts[,"DriversKilled"],type="l", ylab="injured", xlab="Time")
lines(Im(yFitted), col="purple", lwd=2, lty=2)
```

While the model has already captured the relations in the data well, there is still some structure left, which becomes apparent from the analysis of the ACF/PACF in the residuals (Figure \@ref(fig:)).

```{r seatbeltsDataModel1ACF, fig.cap="ACF/PACF of the residuals of the first model.", echo=FALSE}
par(mfcol=c(2,2),mar=c(4,4,1,1))
plot(SeatbeltscLR01,c(10,11), main="")
```

It is hard to understand what specifically is missing in the residuals, so we will fit several cARIMA models with maximum order of 1 for each p, d, and q:

```{r}
cARIMAOrders <- as.matrix(expand.grid(c(0,1),c(0,1),c(0,1)))
colnames(cARIMAOrders) <- c("AR","I","MA")
SeatbeltscLRList <- vector("list",nrow(cARIMAOrders))
names(SeatbeltscLRList) <- paste0("ARIMA(",apply(cARIMAOrders, 1, paste0, collapse=","),")")

for(i in 1:nrow(cARIMAOrders)){
    SeatbeltscLRList[[i]] <- clm(I(clog(y))~log(kms)+log(PetrolPrice)+law+seasonal,
                                 SeatbeltsComplex, orders=cARIMAOrders[i,], maxeval=1000)
}
```

After that we can see which of the models is more appropriate for the data based on the AICc:

```{r}
# Select the best model
iBest <- which.min(sapply(SeatbeltscLRList, AICc))
# Produce summary.
# We specify stepSize for the Hessian calculation
# to make sure that we get reasonable standard errors
summary(SeatbeltscLRList[[iBest]], stepSize=1e-6)
```

The output above has a clear interpretation:

1. With the increase of distance driven by 1%, the number of killed and injured drivers tends to decrease on average by `r abs(round(Re(coef(SeatbeltscLRList[[iBest]]))[2],3))`% and `r abs(round(Im(coef(SeatbeltscLRList[[iBest]]))[2],3))`% respectively;
2. The 1% increase in average petrol price leads to the decrease in the number of killed and injured drivers by `r abs(round(Re(coef(SeatbeltscLRList[[iBest]]))[3],3))`% and `r abs(round(Im(coef(SeatbeltscLRList[[iBest]]))[3],3))`% respectively;
3. The introduction of law on mandatory seatbelts has reduced the number of killed and injured drivers by approximately 10% each;

While we could fit two independent regression models instead of one complex-valued, it would not be able to capture the cARIMA elements the way they are captured in the model above. Arguably, number of killed and injured drivers have a complex dynamic relation, which is captured by the `r SeatbeltscLRList[[iBest]]$other$arima` part of the model.

Finally, we can see how the model fits the data and compare it with the previous one (Figure \@ref(fig:seatbeltsDataModelFinal)).

```{r seatbeltsDataModelFinal, fig.cap="Number of drivers killed and injured and the fitted values from the cARIMA(1,0,1) model.", echo=FALSE}
yFitted <- ts(cexp(fitted(SeatbeltscLRList[[iBest]])), start=yStart, frequency=yFreq)

par(mfcol=c(2,1),mar=c(4,4,1,1))
plot(Seatbelts[,"DriversKilled"],type="l", ylab="killed", xlab="Time")
lines(Re(yFitted), col="purple", lwd=2, lty=2)

plot(Seatbelts[,"drivers"]-Seatbelts[,"DriversKilled"],type="l", ylab="injured", xlab="Time")
lines(Im(yFitted), col="purple", lwd=2, lty=2)
```

Arguably, the model fit is better due to the capture of dynamic elements that were missing in the cLR before.


<!-- ## Forecasting with complex regression models -->


