# Multiple Complex Linear Regression {#multipleCLR}
We now move to the discussion of the multiple CLR, the model that captures relations between one complex random variable, $y_r + i y_i$ and a set of explanatory complex random variables.

## Model formulation 
Similarly to how the multiple linear regression is formulated for real valued variables, the multiple complex linear regression can be written as:
\begin{equation}
    y_j = \beta_0 + \beta_1 x_{1,j} + \beta_2 x_{2,j} + \dots + \beta_k x_{k,j} + \epsilon_j,
    (\#eq:MultipleCLRComplex)
\end{equation}
where $k$ is the number of complex random variables. Similarly to how it was done with SCLR in \@ref(eq:SimpleCLRSystem), we can expand the formula \@ref(eq:MultipleCLRComplex) as a system of two equations, taking that every parameter and every variable in \@ref(eq:MultipleCLRComplex) is complex:
\begin{equation}
    \begin{aligned}
        y_{r,j} = & \beta_{0,r} + \beta_{1,r} x_{1,r,j} - \beta_{1,i} x_{1,i,j} + \dots + \beta_{k,r} x_{k,r,j} - \beta_{k,i} x_{k,i,j} \epsilon_{r,j} \\
        y_{i,j} = & \beta_{0,i} + \beta_{1,r} x_{1,i,j} + \beta_{1,i} x_{1,r,j} + \dots + \beta_{k,r} x_{k,i,j} + \beta_{k,i} x_{k,r,j} + \epsilon_{i,j} .
    \end{aligned}
    (\#eq:MultipleCLRSystem)
\end{equation}
As can be seen from \@ref(eq:MultipleCLRSystem), the multiple CLR captures more complex dynamics than the conventional multiple linear regression. Both parts of the system use the same set of parameters and explanatory variables, but in different combinations, resulting in a versatile modelling framework. Furthermore, this system can also be used to represent the multiple CLR in a simple form using vector and matrix notations:
\begin{equation}
    \mathbf{y}_j = \mathbf{X}_j \boldsymbol{\beta} + \boldsymbol{\epsilon}_j ,
    (\#eq:MultipleCLRSystemVector)
\end{equation}
where $\mathbf{y}_j = \begin{pmatrix} y_{j,r} \\ y_{j,i} \end{pmatrix}$, $\mathbf{X}_j = \begin{pmatrix} 1 & 0 & x_{1,r,j} & -x_{1,i,j} & \dots & x_{k,r,j} & -x_{k,i,j} \\ 0 & 1 & x_{1,i,j} & x_{1,r,j} & \dots & x_{k,i,j} & x_{k,r,j} \end{pmatrix}$ and $\boldsymbol{\beta}^\prime = \begin{pmatrix} \beta_{0,r} & \beta_{0,i} & \beta_{1,r} & \beta_{1,i} & \dots & \beta_{1,k} & \beta_{1,k} \end{pmatrix}$. This can be then represented in the even more compact form, using the same principles as discussed in Section \@ref(simpleCLRModel) in formula \@ref(eq:SimpleCLRSystemVectorFinal):
\begin{equation}
    \mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \mathbf{E} 
    (\#eq:CLRSystemVectorFinal)
\end{equation}
with where $\mathbf{Y}=\begin{pmatrix}\mathbf{y}_1 \\ \mathbf{y}_2\\ \vdots \\ \mathbf{y}_n \end{pmatrix}$, $\mathbf{X}=\begin{pmatrix}\mathbf{X}_1 \\ \mathbf{X}_2\\ \vdots \\ \mathbf{X}_n \end{pmatrix}$ and $\mathbf{E}=\begin{pmatrix}\boldsymbol{\epsilon}_1 \\ \boldsymbol{\epsilon}_2\\ \vdots \\ \boldsymbol{\epsilon}_n \end{pmatrix}$. This formula becomes especially useful for multiple CLR because it can be used in the estimation of the model via OLS or CLS in the matrix form. The form \@ref(eq:CLRSystemVectorFinal) sidesteps the complex numbers all together, representing the set of equations in matrices and vectors, containing real numbers only. This is convenient for many purposes and in inference. However, there is also an alternative presentation of the model, which will become useful in further discussions in this chapter:
\begin{equation}
    \underset{\sim}{\mathbf{Y}} = \underset{\sim}{\mathbf{X}} \underset{\sim}{\boldsymbol{\beta}} + \underset{\sim}{\mathbf{E}},
    (\#eq:CLRSystemVectorComplexFinal)
\end{equation}
where $\underset{\sim}{\mathbf{Y}} = \begin{pmatrix} {y}_{1,r} + i {y}_{1,i} \\ {y}_{2,r} + i {y}_{2,i} \\ \vdots \\ {y}_{n,r} + i {y}_{n,i} \end{pmatrix}$, $\underset{\sim}{\mathbf{X}} = \begin{pmatrix} 1 & x_{1,r,1} + i x_{1,i,1} & \dots & x_{k,r,1} + i x_{k,i,1} \\ \vdots & \vdots & \ddots & \vdots \\ 1 & x_{1,r,n} + i x_{1,i,n} & \dots & x_{k,r,n} + i x_{k,i,n} \end{pmatrix}$, $\underset{\sim}{\boldsymbol{\beta}} = \begin{pmatrix} \beta_{0,r} + i \beta_{0,i} \\ \beta_{1,r} + i \beta_{1,i} \\ \vdots \\ \beta_{k,r} + i \beta_{k,i} \end{pmatrix}$ and $\underset{\sim}{\mathbf{E}} = \begin{pmatrix} {\epsilon}_{1,r} + i {\epsilon}_{1,i} \\ {\epsilon}_{2,r} + i {\epsilon}_{2,i} \\ \vdots \\ {\epsilon}_{n,r} + i {\epsilon}_{n,i} \end{pmatrix}$.

So, the main difference of the form \@ref(eq:CLRSystemVectorComplexFinal) from the \@ref(eq:CLRSystemVectorFinal) is that it contains complex numbers inside each of the matrices and vectors.


## Estimation
In order to estimate the parameters of the model \@ref(eq:CLRSystemVectorFinal), we can use the same methods as in the Chapter \@ref(simpleCLR): OLS, CLS and Likelihood. We will write the estimated model as:
\begin{equation}
    \mathbf{Y} = \mathbf{X} \boldsymbol{b} + \mathbf{\hat{E}} ,
    (\#eq:CLRSystemVectorFinalEstimated)
\end{equation}
where $\boldsymbol{b}$ is the estimate of $\boldsymbol{\beta}$ and $\mathbf{\hat{E}}$ is the estimate of $\mathbf{E}$.


### Ordinary Least Squares
The criterion of OLS for multiple CLR can be written as:
\begin{equation}
    \min S(\boldsymbol{b}) = \min \left(\mathbf{\hat{E}}^\prime \mathbf{\hat{E}}\right),
    (\#eq:CLROLSCriterion)
\end{equation}
which can be expanded to:
\begin{equation}
    \begin{aligned}
    S(\boldsymbol{b}) = & \left( \mathbf{Y} - \mathbf{X} \boldsymbol{b} \right)^\prime \left( \mathbf{Y} - \mathbf{X} \boldsymbol{b} \right) = \\
    & \mathbf{Y}^\prime \mathbf{Y} - \mathbf{Y}^\prime \mathbf{X} \boldsymbol{b} - \boldsymbol{b}^\prime \mathbf{X}^\prime \mathbf{Y} + \boldsymbol{b}^\prime \mathbf{X}^\prime \mathbf{X} \boldsymbol{b}
    \end{aligned}. 
    (\#eq:CLROLSCriterionExpanded)
\end{equation}
Taking derivative of \@ref(eq:CLROLSCriterionExpanded) with respect to $\boldsymbol{b}$ and equating it to zero, results in the following system of normal equations:
\begin{equation}
    \mathbf{X}^\prime \mathbf{X} \boldsymbol{b} = \mathbf{X}^\prime \mathbf{Y} ,
    (\#eq:CLROLSSystemOfNormalEquations)
\end{equation}
which gives the classical formula for the estimation of parameters of the model \@ref(eq:CLRSystemVectorFinal):
\begin{equation}
    \boldsymbol{b} = \left( \mathbf{{X}}^\prime \mathbf{X}\right)^{-1} \mathbf{{X}}^\prime \mathbf{Y}
    (\#eq:MCLROLSEstimate)
\end{equation}
Given that \@ref(eq:MCLROLSEstimate) corresponds to the classical OLS, it will maintain all of its conventional properties, i.e. its estimates being unbiased, efficient and consistent. Note that, as discussed Subsection \@ref(complexVariable), the operation of transposition on matrices is equivalent to the multiplication by the conjugate complex number. This means that for the special case of simple CLR, the classical OLS gives the same formula as \@ref(eq:SimpleCLROLSLossParametersMoments). This also means that the same estimates of parameters can be obtained if we estimate the model \@ref(eq:CLRSystemVectorComplexFinal) directly and use the following formula:
\begin{equation}
    \boldsymbol{b} = \left( \underset{\sim}{\mathbf{\tilde{X}}}^\prime \underset{\sim}{\mathbf{X}}\right)^{-1} \underset{\sim}{\mathbf{\tilde{X}}}^\prime \underset{\sim}{\mathbf{Y}} .
    (\#eq:MCLROLSEstimateComplex)
\end{equation}


### Complex Least Squares
As discussed in Section \@ref(SCLREstimation), there is also an alternative approach to estimation of CLR, the Complex Least Squares. In order to get the estimates based on it, we need to apply the same principles as with OLS, but directly to the form \@ref(eq:CLRSystemVectorComplexFinal), i.e. minimise the criterion (which is the same as the one discussed in Subsection \@ref(SCLREstimationCLS)):
\begin{equation}
    \min S(\boldsymbol{b}) = \min \left(\underset{\sim}{\mathbf{E}}^\prime \underset{\sim}{\mathbf{E}}\right).
    (\#eq:CLRCLSCriterion)
\end{equation}
Using the same logic as with OLS, the minimisation of this criterion implies the solution of the following system of normal equations:
\begin{equation}
    \underset{\sim}{\mathbf{X}}^\prime \underset{\sim}{\mathbf{X}} \underset{\sim}{\boldsymbol{b}} = \underset{\sim}{\mathbf{X}}^\prime \underset{\sim}{\mathbf{Y}} ,
    (\#eq:CLRCLSSystemOfNormalEquations)
\end{equation}
which then results to the following formula for the CLS estimate of parameters:
\begin{equation}
    \boldsymbol{b} = \left( \underset{\sim}{\mathbf{{X}}}^\prime \underset{\sim}{\mathbf{X}}\right)^{-1} \underset{\sim}{\mathbf{{X}}}^\prime \underset{\sim}{\mathbf{Y}} .
    (\#eq:MCLROLSEstimate)
\end{equation}
For the simple CLR, the formula \@ref(eq:MCLROLSEstimate) becomes equivalent to \@ref(eq:SimpleCLRCLSLossParameters). The main difference from the OLS, as we can see, is that the CLS does not do multiplication by the conjugate complex numbers.



## Inference

## Diagnostics

## Forecasting

## Examples of application (Production functions)
