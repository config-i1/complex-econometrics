# Complex Dynamic Models {#Dynamic}
In this chapter we consider the application of the complex linear model to time series data. There are different ways how to do that, and we only discuss a few of the straight forward options of how to construct dynamic models. We start with a model with a trend, which has its own features, then discuss complex Autoregression (cAR), then move to the complex Moving Average (cMA) and complex Autoregression with Moving Average (cARMA) and then finish the discussion with the model applied to differences of the data, cARIMA. cARIMA and its sub-models have a lot in common with the vector ARIMA models applied to two time series. The main difference between them is in the matrix of the parameters: in case of the vector models, it is estimated in full (four parameters for two time series), while in case of the complex ARIMA, it contains two times fewer parameters to estimate. Many of the properties of the vector models can be transferred to cARIMA, and many of them have been explained in detail by @Lutkepohl. Still, there are some of them that are specific for the complex models.

In this chapter, we will use index $t$ instead of $j$ to denote that we are applying the model to time series, not to the cross-sectional data.

## Complex model with trend {#DynamicTrend}
One of the simplest ways to introduce dynamics in a complex model is to include a trend. In the real-valued domain this means adding an explanatory variable with the index of the observation:

\begin{equation}
    {y}_t = {\beta}_0 + {\beta}_1 {x}_{1,t} + {\beta}_2 {x}_{2,t} + \dots + {\beta}_{k-1} {x}_{k-1,t} + \gamma t + {\epsilon}_t,
    (\#eq:trendInRealModel)
\end{equation}
where $\gamma$ is the parameter for the trend and the rest of the equation is just a conventional real-valued regression. The trend in this situation is deterministic and linear, meaning that it starts from the beginning of the sample and increases or decreases (depending on the value of the parameter $\gamma$) indefinitely. Adding such trend to the model allows capturing the deterministic trend and neglecting its effect on the values of other parameters in the model. In cLR, the addition of the trend in the additive model is similar and has the same meaning - it will increase linearly indefinitely. Mathematically, cLR with trend can be written as:
\begin{equation}
    \underline{y}_t = \underline{\beta}_0 + \underline{\beta}_1 \underline{x}_{1,t} + \dots + \underline{\beta}_{k-1} \underline{x}_{k-1,t} + \underline{\gamma} t + \underline{\epsilon}_t .
    (\#eq:trendInCLR)
\end{equation}
The more interesting case arises when a multiplicative cLR is considered, i.e. the model with logarithmic transform (as discussed in Section \@ref(assumptionsSpecificationTransformation)):
\begin{equation}
    \ln \underline{y}_t = \underline{\beta}_0 + \underline{\beta}_1 \ln \underline{x}_{1,t} + \dots + \underline{\beta}_{k-1} \ln \underline{x}_{k-1,t} + \underline{\gamma} \ln t + \underline{\epsilon}_t ,
    (\#eq:trendInCLRLogs)
\end{equation}
which is equivalent to:
\begin{equation}
    \underline{y}_t = \exp \underline{\beta}_0 \times \underline{x}_{1,t}^{\underline{\beta}_1} \times \dots \times \underline{x}_{k-1,t}^{\underline{\beta}_{k-1}} \times t^{\underline{\gamma}} \times \exp \underline{\epsilon}_t .
    (\#eq:trendInCLRNonlinear)
\end{equation}
The trend in \@ref(eq:trendInCLRNonlinear) is now non-linear and depending on the specific values of the complex parameter $\underline{\gamma}$ can exhibit exponential, trigonometric or inverse trajectories. Figure \@ref(fig:trendTrajectories) shows several trajectories of the real and the imaginary parts of the response variable with different values of the parameter $\underline{\gamma}$.

```{r trendTrajectories, fig.cap="Different trajectories of trend with different values of the parameter $\\underline{\\gamma}$: 0.5-1.5i, 1.5-0.5i, and 0.5+0.2i.", echo=FALSE}
t <- c(1:100)
par(mfcol=c(2,3), mar=c(2,4,2,1))
t1 <- t^{0.5-1.5i}
plot(Re(t1),main="",type="l",ylab="Re(y)")
title(main=TeX("$\\underline\\gamma=0.5-1.5i$"))
plot(Im(t1),main="",type="l",ylab="Im(y)")
t1 <- t^{1.5-0.5i}
plot(Re(t1),main="",type="l",ylab="Re(y)")
title(main=TeX("$\\underline\\gamma=1.5-0.5i$"))
plot(Im(t1),main="",type="l",ylab="Im(y)")
t1 <- t^{0.5+0.2i}
plot(Re(t1),main="",type="l",ylab="Re(y)")
title(main=TeX("$\\underline\\gamma=0.5+0.2i$"))
plot(Im(t1),main="",type="l",ylab="Im(y)")
```

As we can see, the non-linear transformation gives the cLR flexibility in capturing various types of trends in the data, making it a much more flexible instrument for modelling than the real-valued regressions. Furthermore, this flexibility in the trend can be used in the real-valued models as well, if we substitute all the complex variables and parameters (except for $\underline{\gamma}$) by their real-valued counterparts. The model will then produce a complex response variable, the imaginary part of which can be dropped.

To better understand how the cLR model with the trend works, we can represent it in the exponential form:
\begin{equation}
    t^{\underline{\gamma}} = \exp (\underline{\gamma} \ln t) = t^{\gamma_r} \exp (i \gamma_i \ln t),
    (\#eq:trendExp)
\end{equation}
where $\underline{\gamma}=\gamma_r + i \gamma_i$. The form \@ref(eq:trendExp) shows that the real part of the parameter $\underline{\gamma}$ controls the magnitude of the resulting complex variable, while the imaginary one controls how fast the argument (angle) changes. So, the more stable trajectories (closer to the linear ones) will be obtained with $\gamma_i$ close to zero, while the speed of the change in the trajectory is regulated by $\gamma_r$.

Another way to look at the complex-valued trend is to use the trigonometric form of complex variable:
\begin{equation}
    t^{\underline{\gamma}} = t^{\gamma_r} \left(\cos (\gamma_i \ln t) + i \sin (\gamma_i \ln t) \right) .
    (\#eq:trendTrig)
\end{equation}
This form tells us that fundamentally any trajectory from the complex-valued trend is trigonometric, but $\gamma_i$ regulates the strength of the cosine/sine waves for the respective real and imaginary parts of the complex response variable.

### Example in R
In R, the trend is supported in the `clm()` function from the `complex` package via the formula. Here is an example:
```{r}
# Set random seed for reproducibility
set.seed(41)
# Sample size
obs <- 100
# Create an explanatory variable
x <- complex(real=rnorm(obs,100,10), imaginary=rnorm(obs,50,5))
# Generate parameters
b0 <- 2 + 1.5i
b1 <- 0.8 - 0.4i
b2 <- 0.5 + 0.2i
# Generate error term from the complex normal distribution
e <- rcnorm(obs, 0, sigma2=0.25, varsigma2=0.16+0.09i)
# Generate the data using non-linear model
y <- exp(b0 + b1 * log(x) + b2 * log(c(1:obs)) + e)
# Merge it to the matrix
complexData <- data.frame(y=y,x=x)
```

The code above will generate data with a slowly increasing trend (similar to the one shown in Figure \@ref(fig:trendTrajectories)), which is shown in Figure \@ref(fig:dataWithTrend)

```{r dataWithTrend, fig.cap="Generated time series with a trend.", echo=FALSE}
par(mfcol=c(2,1), mar=c(4,4,1,1))
plot(Re(complexData$y), typ="l", main="",
     xlab="Time", ylab="Real part")
plot(Im(complexData$y), typ="l", main="",
     xlab="Time", ylab="Imaginary part")
```

Applying a complex linear regression to the data with the same formula as in the DGP gives us the following estimates of parameters:

```{r}
# Apply a model with the trend in logarithms
clrModel <- clm(log(y)~log(x)+log(trend), complexData, subset=1:80)
summary(clrModel)
```

The resulting model fit and the forecast for the next 20 observations are shown in Figure \@ref(fig:dataWithTrendForecast):

```{r dataWithTrendForecast, fig.cap="cLR applied to the generated data with a trend."}
# Extract fitted values and transform to the original scale
fitted(clrModel) |> exp() -> yFitted
yForecast <- predict(clrModel, newdata=tail(complexData, 20))

# Setup the canvas
par(mfcol=c(2,1), mar=c(4,4,1,1))
# Plot the real part
plot(Re(complexData$y), type="l",
     xlab="Time", ylab="Real part")
lines(Re(yFitted), col="purple", lwd=2, lty=2)
exp(yForecast$mean) |> Re() |>
    lines(x=c(81:100), col="blue", lwd=2, lty=2)

# Plot the imaginary part
plot(Im(complexData$y), type="l",
     xlab="Time", ylab="Imaginary part")
lines(Im(yFitted), col="purple", lwd=2, lty=2)
exp(yForecast$mean) |> Im() |>
    lines(x=c(81:100), col="blue", lwd=2, lty=2)
```

As we can see, this example shows how a non-linear trend can be estimated and then used for forecasting using a complex linear regression model.


## Complex AR
One of the possible ways of modelling dynamics is by saying that future values of the variable depend on its past ones. @Box1976, who have developed a theory and methodology of so called "AutoRegressive Integrated Moving Average" (or ARIMA), provide an example of a series of CO$_2$ output by a furnace with variable gas rate. In that situation the future amount of carbon dioxide will depend on the amount the furnace produced on the previous observations. This is one of example of an AR process. An interested reader is directed to Chapter 8 of @SvetunkovAdam, where the ARIMA model is discussed in more detail.

cLR can also be extended by the inclusion of the past values of the response variable. In that case, mathematically the model looks more similar to vector AR rather than the univariate one. However, in our case the model is restricted with just two time series and can still be represented using complex variables:
\begin{equation}
    \underline{y}_t = \underline{\beta}_0 + \underline{\phi}_1 \underline{y}_{t-1} + \dots + \underline{\phi}_p \underline{y}_{t-p} + \underline{\epsilon}_t ,
    (\#eq:ComplexAR)
\end{equation}
where $\phi_j$ is the $j$-th parameter, and $p$ is the order of the model, complex autoregression, cAR(p). The same model can be rewritten in the conventional polynomial form using a backshift operator $B$:
\begin{equation}
    \left(1 - \underline{\phi}_1 B + \dots + \underline{\phi}_p B^p \right) \underline{y}_t  = \underline{\beta}_0 + \underline{\epsilon}_t .
    (\#eq:ComplexARPolynomial)
\end{equation}
This form is convenient for what follows, e.g. for the discussion of unit roots calculation. But also, if we add the already discussed static elements to the right-hand side of \@ref(eq:ComplexAR) or \@ref(eq:ComplexARPolynomial), namely $\underline{\beta}_1 \underline{x}_{1,t} + \dots + \underline{\beta}_{k-1} \underline{x}_{k-1,t}$, then the model will transform into cARX(p), combining the properties of the cLR and cAR.

Similarly to the conventional AR, it can be shown how complex ACF/PACF (discussed in Subsection \@ref(assumptionsResidualsAuto)) behave for different orders of cAR. In this monograph, for simplicity, we only provide an example of cAR(1) without an intercept, noting that the logic for the higher orders is similar [@SvetunkovAdam has similar derivations for the real-valued AR(p) in Section 8.3].

The cAR(1) model is defined as:
\begin{equation}
    \underline{y}_t = \underline{\phi}_1 \underline{y}_{t-1} + \underline{\epsilon}_t .
    (\#eq:ComplexAR1Step1)
\end{equation}
The covariance between the most recent and the previous observations can then be calculated as (note here that we provide the formula for the conjugate covariance, but the calculations for the direct one will be similar):
\begin{equation}
    \mathrm{cov} \left(\underline{y}_t, \underline{y}_{t-1} \right) = \mathrm{cov} \left(\underline{\phi}_1 \underline{y}_{t-1} + \underline{\epsilon}_t, \underline{y}_{t-1} \right) ,
    (\#eq:ComplexAR1Step2)
\end{equation}
which given the basic assumptions of models (Section \@ref(assumptionsResiduals)) equals to:
\begin{equation}
    \mathrm{cov} \left(\underline{y}_t, \underline{y}_{t-1} \right) = \underline{\phi}_1 \mathrm{cov} \left( \underline{y}_{t-1}, \underline{y}_{t-1} \right) .
    (\#eq:ComplexAR1Step3)
\end{equation}
Now, depending on the type of covariance we need, we get:

1. For the conjugate one:
\begin{equation}
    \mathrm{cov}\left(\underline{y}_t, \underline{y}_{t-1} \right) = \underline{\phi}_1 \sigma^2_{y_t} ;
    (\#eq:ComplexAR1ConjCov)
\end{equation}
2. For the direct one:
\begin{equation}
    cov \left(\underline{y}_t, \underline{y}_{t-1} \right) = \underline{\phi}_1 \varsigma^2_{y_t} .
    (\#eq:ComplexAR1DirCov)
\end{equation}
If we now insert \@ref(eq:ComplexAR1ConjCov) and \@ref(eq:ComplexAR1DirCov) into the respective formulae for the conjugate and direct correlations (Section \@ref(correlationTypes), equations \@ref(eq:correlationConjugate) and \@ref(eq:correlationDirect)), we will get the values of the cACF for the first lag according to:

1. Conjugate correlation:
\begin{equation}
    \rho(1) = \frac{\sqrt{\underline{\phi}_1 \sigma^2_{y_t} \underline{\phi}_1 \sigma^2_{y_t}}}{\sigma_{y_t}^2} = | \underline{\phi}_1 |;
    (\#eq:ComplexAR1ConjCor)
\end{equation}

2. Direct correlation:
\begin{equation}
    \varrho(1) = \frac{\underline{\phi}_1 \varsigma^2_{y_t}}{\varsigma^2_{y_t}} = \underline{\phi}_1.
    (\#eq:ComplexAR1DirCor)
\end{equation}

As we can see from the formula \@ref(eq:ComplexAR1ConjCor), the specific value of the cAR(1) parameter is lost because of the geometric mean in the formula: we end up with a magnitude of the complex variable instead of it real and imaginary parts. On the other hand, the direct cACF \@ref(eq:ComplexAR1DirCor) keeps the information about the cAR(1) parameter. However, the two formulae above are calculated in terms of expectations and their sample estimates might be slightly different. Specifically, the direct correlation \@ref(eq:ComplexAR1DirCor) relies on the sample estimate of the direct variance of the response variable $y_t$, which might become equal to zero if the variances of the real and the imaginary parts of the complex variable are similar (as discussed in Section \@ref(correlationDirect)). This means that in some situations the values of the direct cACF might become greater than one, leading to potential losses in information. But this also means that both conjugate and direct cACFs should be used for the analysis of complex time series: each of them has issues, but both of them give much clearer information about the potential process.

If we calculate the covariance for the cAR(1) between the values $y_{t}$ and $y_{t-2}$, we will get the following (the reader is encouraged to do the calculations manually to check the correctness of the final result):

1. Conjugate correlation:
\begin{equation}
    \rho(2) = | \underline{\phi}_1^2 |;
    (\#eq:ComplexAR1ConjCor)
\end{equation}

2. Direct correlation:
\begin{equation}
    \varrho(2) =  \underline{\phi}_1^2.
    (\#eq:ComplexAR1DirCor)
\end{equation}

In principles, it can be shown that the main properties of real-valued AR discussed by @Box1976 hold widely for the cAR processes: cACF will decline exponentially starting from the lag p.

The more useful (at least potentially) property for cAR(p) is the behaviour of the cPACF. This function shows the relations between specific lags without the effect of all the interim lags, i.e. cleaned from the autocorrelations between the neighbouring lags. One of ways of calculating the cPACF for a lag $\tau$ is to estimate the following model:
\begin{equation}
    \underline{y}_t = \underline{\phi}_1 \underline{y}_{t-1} + \dots + \underline{\phi}_\tau \underline{y}_{t-\tau} + \underline{\epsilon}_t
    (\#eq:cPACFModel)
\end{equation}
and getting the coefficient $\underline{\phi}_\tau$. Repeating this procedure for all lags of interest, we get a cPACF. The model \@ref(eq:cPACFModel) can be estimated using OLS or CLS, which will result in respective conjugate and direct cPACF.

It can be shown that for the cAR(p) process, both conjugate and direct cPACF will drop to zero abruptly after the lag p and that both of them will produce complex numbers, reflecting the respective parts of the coefficients of the cAR(p) model. However, the direct cPACF might have issues similar to the ones the direct cACF has if the variances of the real and the imaginary parts of the response variable are close to each other.

As we see, the complex AR(p) has similar properties to the real-valued one, but it should be analysed using both conjugate and direct cACF/cPACF.

Finally, in Box-Jenkins methodology, it is important for the AR(p) processes to be stationary, otherwise they become explosive and cannot be efficiently identified at the model building stage. The stationarity condition for AR(p) in @Box1976 is that the roots of the polynomial formed from the parameters of the AR model should all lie outside the unit circle. For AR(1) this simplifies to $|\phi_1|<1$. The same conditions hold for the cAR(p) processes, meaning that the magnitudes of the complex parameters are considered. For the cAR(1), the stationarity condition is $|\underline{\phi}_1|<1$. But more widely, for cAR(p), it is that the roots of the following polynomial:
\begin{equation}
    1 - \underline{\phi}_1 x - \underline{\phi}_2 x^2 - \dots - \underline{\phi}_p x^p = 0
    (\#eq:ComplexARPolyRoots)
\end{equation}
should all lie outside the unit circle (be greater than one by absolute value).


### Example in R
For demonstration purposes we consider the cAR(1) process to see how cACF/cPACF and the data will look
```{r}
# Sample size
set.seed(41)
# Number of observations
obs <- 110
# Parameters
b0 <- 100+50i
phi1 <- 0.5 + 0.2i
# Complex white noise
y <- rcnorm(obs, 0, sigma2=25, varsigma2=16+9i)
# Initial value
y[1] <- b0 + y[1]
# The cAR(1)
for(i in 2:obs){
    y[i] <- phi1 * y[i-1] + y[i] + b0
}
# Drop the first 10 observations as a burn-in period
y <- y[-c(1:10)]
```

The conjugate cACF/cPACF are shown in Figures \@ref(fig:complexAR1cACF) and \@ref(fig:complexAR1cPACF):

```{r complexAR1cACF, fig.cap="Conjugate cACF of the complex AR(1)."}
cacf(y, method="conjugate")
```

As we see from Figure \@ref(fig:complexAR1cACF), the cACF declines after the lag 1. Notably, the cACF for lag one equals to `r round(cacf(y, method="conjugate", plot=FALSE)$acf[1],3)`, which is close to the true value of the magnitude of the parameter $\phi_1=0.5+0.2i$ is `r abs(phi1)`.

```{r complexAR1cPACF, fig.cap="Conjugate cPACF of the complex AR(1)."}
cpacf(y, method="conjugate")
```

The cPACF in Figure \@ref(fig:complexAR1cPACF) demonstrates that both the real and the imaginary values drop to zero after the first observation, as expected for the AR(1) process. Notably, the value of the first cPACF is `r round(cpacf(y, method="conjugate", plot=FALSE)$acf[1],3)`, which is close to the true value of the parameter.

Finally, the plot in Figure \@ref(fig:complexAR1Plot) shows the generated data on the complex plane and the dynamics of obth the real and the imaginary parts.

```{r complexAR1Plot, fig.cap="Visualisation of the cAR(1) process.", echo=FALSE}
layout(matrix(c(1,2,1,3),2,2))
par(mar=c(4,4,1,1))
plot(y, type="b", main="")
plot(Re(y), type="l", xlab="Time", main="")
plot(Im(y), type="l", xlab="Time", main="")
```

When it comes to applying a model and to forecasting, the same `clm()` function from the `complex` package in R can be used:

```{r}
# Shift the response variable to create the lagged explanatory variable
complexData <- xregExpander(complex2vec(y), lags=-1)
# Form the complex data frame
complexData <- data.frame(y=vec2complex(complexData[,c(1,3)]),
                          yLag1=vec2complex(complexData[,c(1,3)+1]))
colnames(complexData) <- c("y","yLag1")
# Fit the model
cAR1Model <- clm(y~., complexData, subset=c(1:80))
# Generate the summary
summary(cAR1Model)
```

The output above shows the estimates of parameters of the model, demonstrating that the OLS produced estimates close to the true values of parameters (as expected). After that we can generate forecast for the next 20 observations:

```{r}
# Vector of forecasts
yForecast <- vector("complex", 20)
# The data frame for the future values
complexData20 <- tail(complexData,20)
complexData20$y[] <- NA
complexData20$yLag1[2:20] <- NA

# Iteative loop to produce one-step-ahead forecasts
for(i in 1:20){
    cAR1ModelForecast <- predict(cAR1Model, newdata=complexData20[i,])
    yForecast[i] <- cAR1ModelForecast$mean
    if(i<20){
        # Write down the forecast as the new lagged value
        complexData20$yLag1[i+1] <- cAR1ModelForecast$mean
    }
}
```

Unfortunately, the process of forecast generation is not yet automated in the functions of the `complex` package, so the code above demonstrates how this can be done manually in an iterative fashion, making sure that there is no holdout values leackage in the process. The forecasts are shown in Figure \@ref(fig:complexAR1Forecast).

```{r complexAR1Forecast, fig.cap="Forecasts for the cAR(1) process."}

# Produce the plot of the data and the forecasts
par(mfcol=c(2,1),mar=c(4,4,1,1))
plot(Re(y), type="l", xlab="Time", main="")
lines(81:100, Re(yForecast), col="blue", lwd=2)
plot(Im(y), type="l", xlab="Time", main="")
lines(81:100, Im(yForecast), col="blue", lwd=2)
```

As we can see, the forecast trajectory from the cAR(1) model corresponds to the dampening line, which is a behaviour similar to the conventional real-valued AR(1) model [e.g. discussed in Subsection 8.1.1 of @SvetunkovAdam].


## Complex MA
New thing. Base it on ADAM ARIMA discussion


## Complex ARMA and ARIMA
From 2.4


## Non-linear cARIMA


## Other possible models
Other stuff from the original monograph
